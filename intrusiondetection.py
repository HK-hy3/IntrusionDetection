# -*- coding: utf-8 -*-
"""IntrusionDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bsPbDdNkogcsvf4Wiy2N66GT6-Qwnt6_
"""

#Preprocessing of Datasets and Training the SVM model on 4 different kernels
import joblib
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    classification_report,
    confusion_matrix
)

train_data = pd.read_csv('KDDTrain.txt', header=None)
test_data = pd.read_csv('KDDTest.txt', header=None)

print("Training Data Shape:", train_data.shape)
print("Testing Data Shape:", test_data.shape)

columns = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',
          'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',
          'logged_in', 'num_compromised', 'root_shell', 'su_attempted',
          'num_root', 'num_file_creations', 'num_shells', 'num_access_files',
          'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count',
          'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',
          'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',
          'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',
          'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',
          'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',
          'dst_host_srv_serror_rate', 'dst_host_rerror_rate',
          'dst_host_srv_rerror_rate', 'label', 'difficulty_level']

train_data.columns = columns
test_data.columns = columns

# View sample data
print(train_data.head())

# Preprocessing Step

# Drop 'difficulty_level' (Not useful for training)
train_data = train_data.drop('difficulty_level', axis=1)
test_data = test_data.drop('difficulty_level', axis=1)

# Encode categorical variables
label_encoder = LabelEncoder()
for column in ['protocol_type', 'service', 'flag', 'label']:
   combined_data = pd.concat([train_data[column], test_data[column]], axis=0)
   label_encoder.fit(combined_data)
   train_data[column] = label_encoder.transform(train_data[column])
   test_data[column] = label_encoder.transform(test_data[column])

# Separate features and labels
X_train = train_data.drop('label', axis=1)
y_train = train_data['label']
X_test = test_data.drop('label', axis=1)
y_test = test_data['label']

# Normalize the numeric data
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Data preprocessing completed successfully!")

# Train the SVM model with a linear kernel
svm_linear = SVC(kernel='linear')
svm_linear.fit(X_train, y_train)
joblib.dump(svm_linear, 'svm_linear.pkl')

# Predict using the model
y_pred_linear = svm_linear.predict(X_test)

# Evaluate the model
# print("Accuracy (Linear Kernel):", accuracy_score(y_test, y_pred_linear))
# print("Classification Report:\n", classification_report(y_test, y_pred_linear))
# print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_linear))


#Output :
#The model was trained using a Linear Kernel SVM and achieved an accuracy of 70.49% on the test dataset.
#However, the classification report indicates significant performance issues, particularly for certain attack classes. Several classes have 0.0 precision and recall, suggesting the model failed to detect or predict those attacks.
#The warnings indicate that some classes had no predicted samples, which is often due to class imbalance or the model's inability to separate complex patterns using a linear kernel.
#Despite this, the model showed good recall for a few dominant classes, meaning it detected those attacks effectively.
#The confusion matrix highlights misclassifications, especially for minority classes, indicating that further optimization is needed.'


# RBF Kernel
clf_rbf = SVC(kernel='rbf')
clf_rbf.fit(X_train, y_train)
y_pred_rbf = clf_rbf.predict(X_test)
print("Accuracy (RBF Kernel):", accuracy_score(y_test, y_pred_rbf))
joblib.dump(clf_rbf, 'svm_rbf.pkl')

# Polynomial Kernel
clf_poly = SVC(kernel='poly', degree=3)  # Degree can be adjusted
clf_poly.fit(X_train, y_train)
y_pred_poly = clf_poly.predict(X_test)
print("Accuracy (Polynomial Kernel):", accuracy_score(y_test, y_pred_poly))
joblib.dump(clf_poly, 'svm_poly.pkl')

# Sigmoid Kernel
clf_sigmoid = SVC(kernel='sigmoid')
clf_sigmoid.fit(X_train, y_train)
y_pred_sigmoid = clf_sigmoid.predict(X_test)
print("Accuracy (Sigmoid Kernel):", accuracy_score(y_test, y_pred_sigmoid))
joblib.dump(clf_sigmoid, 'svm_sigmoid.pkl')


#Data Overview: You trained the SVM on 125,973 samples and tested it on 22,544 samples with 43 features.
#Linear Kernel: Gave an accuracy of 70.49%.
#RBF Kernel: Slightly lower accuracy of 69.70%.
#Polynomial Kernel: Almost similar to RBF, with an accuracy of 69.67%.
#Sigmoid Kernel: Performed the worst, with an accuracy of 68.94%.

#Observations:
#The Linear Kernel performed the best, likely due to the data being somewhat linearly separable.
#RBF and Polynomial Kernels were close in performance, indicating non-linear relationships exist in the data.
#Sigmoid Kernel often struggles on large datasets, which explains its lowest accuracy

# Evaluation of the saved model
import numpy as np
import joblib
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    classification_report,
    confusion_matrix
)

# Evaluation function
def evaluate_model(name, model, X_test, y_test):
    y_pred = model.predict(X_test)
    print(f"\n Evaluation Results for {name.upper()} Kernel:")
    print(f"Accuracy : {accuracy_score(y_test, y_pred):.4f}")
    print(f"Precision: {precision_score(y_test, y_pred, average='weighted', zero_division=0):.4f}")
    print(f"Recall   : {recall_score(y_test, y_pred, average='weighted', zero_division=0):.4f}")
    print(f"F1-Score : {f1_score(y_test, y_pred, average='weighted', zero_division=0):.4f}")
    print("ðŸ§® Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("\n Detailed Classification Report:")
    print(classification_report(y_test, y_pred, zero_division=0))

# Load test data
X_test = np.load("X_test.npy")
y_test = np.load("y_test.npy")

# Define model names
kernels = ["linear", "poly", "rbf", "sigmoid"]

# Evaluate each saved model
for kernel in kernels:
    model_path = f"svm_{kernel}.pkl"
    model = joblib.load(model_path)
    evaluate_model(kernel, model, X_test, y_test)

#Explain.py

import shap
import joblib
import numpy as np
import matplotlib.pyplot as plt
X_train = np.load("X_train.npy")
X_test = np.load("X_test.npy")
column_names = [ "duration", "protocol_type", "service", "flag", "src_bytes", "dst_bytes",
    "land", "wrong_fragment", "urgent", "hot", "num_failed_logins", "logged_in",
    "num_compromised", "root_shell", "su_attempted", "num_root", "num_file_creations",
    "num_shells", "num_access_files", "num_outbound_cmds", "is_host_login",
    "is_guest_login", "count", "srv_count", "serror_rate", "srv_serror_rate",
    "rerror_rate", "srv_rerror_rate", "same_srv_rate", "diff_srv_rate",
    "srv_diff_host_rate", "dst_host_count", "dst_host_srv_count",
    "dst_host_same_srv_rate", "dst_host_diff_srv_rate",
    "dst_host_same_src_port_rate", "dst_host_srv_diff_host_rate",
    "dst_host_serror_rate", "dst_host_srv_serror_rate",
    "dst_host_rerror_rate", "dst_host_srv_rerror_rate" ]

kernel_names = ["linear", "poly", "rbf", "sigmoid"]
for kernel in kernel_names:
    print(f"\n SHAP summary for {kernel.upper()} kernel")

    # Load model
    model = joblib.load(f"svm_{kernel}.pkl")

    # Use SHAP KernelExplainer for SVM
    explainer = shap.KernelExplainer(model.predict, X_train[:100])  # Use a small background set
    shap_values = explainer.shap_values(X_test[:100], nsamples=100)  # Limit for speed

    # SHAP Summary Plot
    shap.summary_plot(shap_values, X_test[:100], feature_names=column_names, show=False)
    plt.title(f"SHAP Summary Plot - {kernel.upper()} Kernel")
    plt.savefig(f"Shap3_{kernel}.png")
    plt.close()

    print(f"Saved: shap_{kernel}.png")

"""Here is a summary of the **SHAP GRAPHS** for each kernel:

**1. Linear Kernel:**
*Top Influential Features:*

dst_host_count, dst_host_same_srv_rate, dst_host_srv_diff_host_rate, dst_host_rerror_rate, serror_rate

*Interpretation:*

Features like dst_host_count and dst_host_same_srv_rate have a strong influence.

Red dots (high values) on the right indicate that high feature values push the prediction toward "attack", while blue (low values) on the left show they push toward "normal".

The wide spread of SHAP values (x-axis) for these features indicates they significantly affect the model's decision.

**2. Poly Kernel**
Top Influential Features:

dst_host_same_srv_rate, dst_host_count, rerror_rate, dst_host_srv_serror_rate, srv_serror_rate

*Interpretation:*

The poly kernel picks up complex, nonlinear interactions.

dst_host_same_srv_rate again plays a major role, indicating this feature consistently impacts the prediction across models.

High feature values (red) again shift predictions positively (toward attack), while low values (blue) may reduce the risk score.

**3. RBF Kernel **


Top Influential Features:

dst_host_count, dst_host_srv_count, srv_diff_host_rate, flag, protocol_type

*Interpretation:*

RBF focuses on local structure in data and seems to distribute importance across a slightly broader set of features.

While dst_host_count is again top-ranked, features like flag, protocol_type, and src_bytes start playing stronger roles here.

The SHAP values are more concentrated around zero, suggesting the RBF model may make more conservative decisions compared to others.

**4. Sigmoid Kernel:**


Top Influential Features:

dst_host_count, dst_host_same_srv_rate, dst_host_srv_diff_host_rate, serror_rate, protocol_type

*Interpretation:*

The sigmoid kernel's behavior lies somewhere between linear and RBF. It still prioritizes dst_host_count and related host-based traffic metrics.

The SHAP values range more widely here (up to Â±10), meaning the sigmoid model reacts more sharply to certain features.

protocol_type and srv_diff_host_rate also emerge as significant.

**Conclusion**
dst_host_count is the most influential feature across all kernels.

Linear and polynomial kernels rely heavily on host-based and connection rate features.

RBF and sigmoid kernels begin to factor in connection details like protocol_type and flag.

The spread of SHAP values gives insight into model sensitivity: sigmoid and poly models are more sensitive than RBF
"""

